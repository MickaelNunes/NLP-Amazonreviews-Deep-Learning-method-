{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "with open('src/amazon_reviews.txt') as inputfile:\n",
    "    for line in inputfile:\n",
    "        X.append(line.strip().split('   ')[0][11:])\n",
    "        y.append(int(line.strip().split('   ')[0][9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par préparer les données afin qu'elles soient utilisables par un algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def token(text):\n",
    "    words = set(text_to_word_sequence(text))\n",
    "    return one_hot(text, 10000)\n",
    "    \n",
    "X_token = [token(X[i]) for i in range(len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    if y[i] == 2:\n",
    "        y[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel genre de commentaires avons-nous finalement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X[0]))\n",
    "len(X_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(X_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.9356\n",
      "207\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "lenght = [len(X_token[i]) for i in range(len(X_token))]\n",
    "\n",
    "print(sum(lenght)/len(lenght))\n",
    "print(max(lenght))\n",
    "print(min(lenght))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_token, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "                                    value=0,\n",
    "                                    padding='post', \n",
    "                                    maxlen=100) \n",
    "\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "                                   value=0,\n",
    "                                   padding='post', \n",
    "                                   maxlen=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons lui maintenant un réseau de neuronnes de type RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, LSTM, Dense, Embedding\n",
    "\n",
    "\n",
    "def GRU_RNN():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=32, input_length=100))\n",
    "\n",
    "    model.add(GRU(units=32, return_sequences=True))\n",
    "    model.add(GRU(units=32, return_sequences=False))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.6912 - acc: 0.5300 - val_loss: 0.6847 - val_acc: 0.5625\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.6379 - acc: 0.6114 - val_loss: 0.6595 - val_acc: 0.6160\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.4989 - acc: 0.7399 - val_loss: 0.4972 - val_acc: 0.7685\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.2931 - acc: 0.8821 - val_loss: 0.4399 - val_acc: 0.8115\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.1857 - acc: 0.9409 - val_loss: 0.5339 - val_acc: 0.8115\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.1237 - acc: 0.9639 - val_loss: 0.5496 - val_acc: 0.8125\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0869 - acc: 0.9790 - val_loss: 0.6307 - val_acc: 0.7990\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0819 - acc: 0.9771 - val_loss: 0.7792 - val_acc: 0.8005\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0599 - acc: 0.9849 - val_loss: 0.9035 - val_acc: 0.7970\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0491 - acc: 0.9891 - val_loss: 0.8246 - val_acc: 0.7995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a34530c88>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRU_RNN()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons donc un gros overfitting... C'est le risque avec ce genre de modèle. Néanmoins, nous pourrions dans un premier temps modifier nos paramètres afin d'améliorer le réultat et combattre l'overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
